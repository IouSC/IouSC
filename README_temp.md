<!-- [![Typing SVG](https://readme-typing-svg.demolab.com?font=Annapurna+SIL&size=24&duration=1000&pause=1005&color=002D72&background=FFFFFF00&center=true&random=false&width=435&height=50&lines=Robotics+M.S.E+at+Johns+Hopkins+University)](https://git.io/typing-svg) -->

<!-- <svg width="400" height="30" xmlns="http://www.w3.org/2000/svg">
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Arnhem');
    text { font-family: 'Arnhem Pro', Georgia, serif; font-size: 24px; fill: #68ACE5; }
  </style>
  <text x="90" y="20">Ching Yang (Austin) Huang</text>
</svg> -->

<h1 align="center">Ching-Yang (Austin) Huang</h1>



<!--  -->
## üßë About Me

Hello! I'm **Ching Yang (Austin) Huang**, a dedicated and passionate Master's student specializing in Robotics at Johns Hopkins University. With a robust foundation in engineering principles and a keen interest in the cutting-edge fields of Automation, Mechatronics, Robotics, Virtual Reality (VR), and Computer Vision, I am on a mission to contribute to the advancement of these technologies.

<!--  -->
## üë®‚Äçüíª Skills

| Category | Skills |
|:-|:-|
| **Programming Languages** | ![Python](https://skillicons.dev/icons?i=py&theme=dark) ![C++](https://skillicons.dev/icons?i=cpp&theme=dark) ![C#](https://skillicons.dev/icons?i=cs&theme=dark) ![Matlab](https://skillicons.dev/icons?i=matlab&theme=dark)|
| **ML, VR, & Robotics** | ![TensorFlow](https://skillicons.dev/icons?i=tensorflow&theme=dark) ![PyTorch](https://skillicons.dev/icons?i=pytorch&theme=dark) ![ROS](https://skillicons.dev/icons?i=ros&theme=dark) ![Unity](https://skillicons.dev/icons?i=unity&theme=dark) ![Gazebo](https://img.shields.io/badge/Gazebo-ffffff?style=for-the-badge&logo=gazebo&logoColor=black) ![MRTK](https://img.shields.io/badge/MRTK-00B2FF?style=for-the-badge&logo=microsoft&logoColor=white) |
| **Development Tools & DevOps** | ![Anaconda](https://skillicons.dev/icons?i=anaconda&theme=dark) ![Arduino](https://skillicons.dev/icons?i=arduino&theme=dark) ![Visual Studio](https://skillicons.dev/icons?i=visualstudio&theme=dark) ![VS Code](https://skillicons.dev/icons?i=vscode&theme=dark) ![Linux](https://skillicons.dev/icons?i=linux&theme=dark) ![Ubuntu](https://skillicons.dev/icons?i=ubuntu&theme=dark) ![Docker](https://skillicons.dev/icons?i=docker&theme=dark) ![AWS](https://skillicons.dev/icons?i=aws&theme=dark) ![Azure](https://skillicons.dev/icons?i=azure&theme=dark) |
| **Design, Simulation & CAD Tools** | ![AutoCAD](https://skillicons.dev/icons?i=autocad&theme=dark) ![Creo](https://img.shields.io/badge/Creo-ED1C24?style=for-the-badge&logo=ptc&logoColor=white) ![Creo Simulation](https://img.shields.io/badge/Creo_Simulation-ED1C24?style=for-the-badge&logo=ptc&logoColor=white) ![SolidWorks](https://img.shields.io/badge/SolidWorks-4A90E2?style=for-the-badge&logo=dassault-systemes&logoColor=white)![Femap](https://img.shields.io/badge/Femap-007ACC?style=for-the-badge&logo=siemens&logoColor=white)|
| **Version Control Systems** | ![Git](https://skillicons.dev/icons?i=git&theme=dark) ![GitHub](https://skillicons.dev/icons?i=github&theme=dark) ![GitLab](https://skillicons.dev/icons?i=gitlab&theme=dark) |
| **Documentation & Project Management** | ![LaTeX](https://skillicons.dev/icons?i=latex&theme=dark) ![Notion](https://skillicons.dev/icons?i=notion&theme=dark) ![Jira](https://img.shields.io/badge/Jira-0052CC?style=for-the-badge&logo=jira&logoColor=white) |




<!--  -->
## üóÑ Projects

### VRPelviSim: Transforming Clinical Practices in Fluoroscopic Surgery with Virtual Reality

- Clinched the **Best Project Award** Finalist presented by the [Engineering Research Center](https://www.nsf.gov/eng/eec/erc.jsp) for Computer-Integrated Surgical Systems and Technology ([CISST ERC](https://cisst.org/)) led by [Dr. Russell H. Taylor](https://engineering.jhu.edu/faculty/russell-taylor/), father of medical robotics.
- VRPelviSim provides an effective, risk-free virtual reality environment that emulates real operating rooms, transforming the landscape of clinical data collection and surgical training in fluoroscopic surgery. Features include user-friendly control panels, intuitive and precise virtual C-arm operations, scalable servers for widespread access, anonymized patient models derived from real CT data, and realistic simulated digital radiography (DRR) images leveraging [DeepDRR](https://doi.org/10.48550/arXiv.1803.08606).
- This project builds upon the groundbreaking research by Killeen et al., detailed in their latest publication, [Stand in surgeon's shoes: virtual reality cross-training to enhance teamwork in surgery](https://doi.org/10.1007/s11548-024-03138-7)
- [Link to poster](https://github.com/AustinHuang823/AustinHuang823/blob/main/assets/materials/team03_final-poster.pdf)
- Tools utilized: Unity, MRTK, C#, Python, ZeroMQ, Docker, AWS/AZURE, Notion, Jira.
- Affiliated skills: VR, User-centric development, Kinematics, Network and Server Deployment, Project Management, Documentation, and Presentation Skills.

<p align="center">
  <img src="/assets/image/VRPelviSim_Team_wMentors.jpeg" alt="VRPelviSim Team with Mentors" height="216" width="288" />
  <img src="/assets/image/VRPelviSim.jpeg" alt="VRPelviSim Environment" height="216" width="347" />
</p>
<p align="center" style="font-size: 10px;">
  <em>VRPelviSim Team with Mentors</em> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <em>VRPelviSim Environment <a href="https://youtu.be/um9RDD8XH9g" target="_blank">Demo Video Link</a></em>
</p>



### Robot Arm Control and Image Drawing Manipulation
- This project showcases the application of complex robotic control algorithms, such as Inverse Kinematics, Transposed-Jacobian, and Resolved-Rate Control, for executing precise pick-and-place tasks. 
- By fine-tuning the algorithms' time steps and gains, efficiency and stability were significantly enhanced. 
- Challenges like table collisions, singularity issues, and workspace limitations were effectively addressed. 
- A highlight of the project was programming the UR5 robot arm to artistically draw the Johns Hopkins University logo, demonstrating both technical mastery and creative application of robotics.
- [Link to the report](https://github.com/AustinHuang823/Robot-Arm-Control-and-Image-Drawing-Manipulation-public)
- Tools utilized: ROS, MATLAB, Ubuntu, Linux.
- Affiliated skills: Kinematics, Control.

<p align="center">
  <img src="/assets/gif/rdkdc_imagedrawing_optimized.gif" alt="JHU logo drawing demo" height="300" width="180" /> <img src="/assets/image/rdkdc_simulation.png" alt="JHU logo drawing trajectory in simulation" height="300" />
</p>
<p align="center" style="font-size: 10px;">
  <em>JHU logo drawing demo</em> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <em>JHU logo drawing trajectory in simulation</em>
</p>


### Calibration and Distortion Correction in Stereotactic Navigation
- This project advanced the domain of stereotactic navigation systems by developing and implementing mathematical models and algorithms for precise calibration, distortion correction, and tracking.
- Techniques included Cartesian 3D points rotations, frame transformations, 3D point cloud registration, pivot calibration, and advanced interpolation for distortion correction utilizing Bernstein polynomials.
- The project emphasized on correcting distortions within the stereotactic navigation system, enabling accurate determination of instrument tip location relative to CT frames, significantly improving the system's accuracy and reliability.
- Validation methods involved detailed statistical analysis and visualization of results, demonstrating the effectiveness of the developed approaches in handling real-world navigation and tracking challenges.
- [Link to the report](https://github.com/AustinHuang823/Calibration-and-Distortion-Correction-in-Stereotactic-Navigation-public)
- Tools utilized: Python.
- Affiliated skills: Interpolation, Calibration, Distortion Correction, Bezier Geometry, Data Processing, Validation.


### Human Perception Enhancement with Head Mounted Display(HMD)
- The project leverages HoloLens 2's Research Mode to enhance object awareness beyond the user's field of view. It features ArUco Marker detection, utilizing environmental cameras for real-time object tracking, and employs a radar mini-map UI for intuitive navigation. 
- [Link to the repo](https://github.com/AustinHuang823/Increase-Human-FoV-Using-Hololens)
- Tools utilized: Unity, C#, ArUco.
- Affiliated skills: VR, UI design.

<p align="center">
  <img src="/assets/image/perception_demo.jpg" alt="Perception Enhancement UI" height="200" />&nbsp;<img src="/assets/gif/perception_demo.gif" alt="Pereception Enhancement Demo" height="200" /> 
</p>
<p align="center" style="font-size: 10px;">
  <em>Perception enhancement UI</em> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <em>Pereception enhancement demo</em>
</p>


### Semantic Segmentation with Transfer Learning
- The project explores the enhancement of semantic segmentation for autonomous driving through transfer learning.
- Utilizing the DeepLabv3+ model, pre-trained on Cityscapes and fine-tuned on the JHUStreet dataset, the project aimed to improve segmentation accuracy in diverse environments. 
- Significant improvements were observed, particularly in detecting cars and traffic signs in urban settings near the Johns Hopkins Homewood campus.
- [Link to the repo](https://github.com/AustinHuang823/Transfer-Learning-in-Semantic-Segmentation)
- Tools utilized: Python.
- Affiliated skills: Pytorch, Data Processing.

<p align="center">
  <img src="/assets/image/segmentation.png" alt="Segmentation mask" height="200" />&nbsp;<img src="/assets/gif/segmentation_optimized.gif" alt="Inference examples in epochs" height="200" /> 
</p>
<p align="center" style="font-size: 10px;">
  <em>Segmentation mask</em> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <em>Inference examples in epochs</em>
</p>


The above examples provided showcase a range of my projects. For those interested in exploring more, such as the `Iterative Closest Point Algorithm for 3D Surface Matching`, `Sensor-Based Robot Arm Control`, `Wireless Climate-controlled Lighting and Blinds System`, `Video Content 3D Model Rebuilt by Structure from Motion`, `Cybersecurity Strengthening with Deep Learning`, `Decision Tree implementation`, `Self-implemented Ransac package`, and other innovative works, please feel free to reach out directly at chuan120@jhu.edu for further details and discussions on these and additional projects.

<!-- ### Iterative Closest Point Algorithm for 3D Surface Matching
- This project focuses on the implementation of the Iterative Closest Point (ICP) algorithm to match 3D surfaces accurately, addressing a crucial challenge in computer-integrated surgery and robotics.
- Developed two nearest neighbor search (NNS) methods: the linear brute-force search for simplicity and the efficient covariance tree search for handling larger datasets with improved time efficiency.
- Employed advanced mathematical models and algorithms for 3D data processing, including point cloud registration and transformation techniques, to ensure precise alignment of 3D surfaces.
- Validation and results analysis demonstrated the effectiveness of these methods in achieving high accuracy and significant improvements in computational efficiency.
- [Link to the report](https://github.com/AustinHuang823/Iterative-Closest-Point-Algorithm-for-3D-Surface-Matching-public)
- Tools utilized: Python.
- Affiliated skills: ICP, Kinematics, Data Processing, Validation. -->

<!-- ### Sensor-Based Robot Arm Control
- Materials under maintainance
- Implemented hand-eye calibration using the Park-and-Martin method, yielding an end effector error of just 0.2mm.

### Wireless Climate-controlled Lighting and Blinds System
- Materials under maintainance

### Video Content 3D Model Rebuilt by Structure from Motion
- Materials under maintainance

### Cybersecurity Strengthening with Deep Learning
- Materials under maintainance

### Decision Tree implementation
- Materials under maintainace -->



<!--  -->
## üíº Experience

Please note that all projects in this scetion are subject to non-disclosure agreements (NDAs), hence further details or documentation cannot be shared.


### Intelligent Inventory Management System Development at NIH 
- During my internship at [Axle Informatics](https://axleinfo.com/), I engaged in a pioneering project at the [National Institute of Health (NIH)](https://www.nih.gov/), aiming at revolutionizing laboratory automation through the development of the Intelligent Inventory Management System (IIMS) and High-Density Storage (HDS). 
- I focused on creating an efficient, automated storage solution, HDS, to address the challenges of manual inventory management in laboratory settings. 
- My contributions spanned hardware design, including space-efficient, user-friendly, and robust storage solutions, and the integration of automation to enhance operational efficiency and accuracy. 
- The project's success was marked by significant advancements in automating pick-and-place tasks and inventory management of laboratory processes, demonstrating the potential to drastically reduce human error and improve drug discovery processes.
- Tools utilized: Creo, Femap, Python, C++, Arduino.
- Affiliated skills: Hardware, Mechatronics, Computer Vision, Control.


### Malaria Vaccine Production Enhancement at LCSR, JHU
- As a Research Assistant at the [Laboratory for Computational Sensing and Robotics (LCSR)](https://lcsr.jhu.edu/) at Johns Hopkins University, under the guidance of Russell Taylor and cooperation with other professors and researchers, I significantly optimized the malaria vaccine production system's setup time by integrating deep learning techniques in computer vision to the system.
- My work led to a substantial enhancement in ROI detection accuracy, reaching 96% using the YOLOv5 model. 
- I implemented Class Activation Mapping with PyTorch by adding a Global Average Pooling layer, enabling us to discern mosquito attributes more effectively, thereby improving vaccine quality with a 95% accuracy rate in predicting vaccine efficacy.
- I streamlined the development process by automating data preparation with Python, centralizing configuration through JSON, enforcing version control with Git, and ensuring comprehensive codebase documentation, thereby boosting overall task efficiency for collaboration.
- Tools utilized: Python, PyTorch, YOLO, Git, GitLab.
- Affiliated skills: Deep Learning, Computer Vision, Automation, Data Processing.


### Clash Bots

- [Clash Bots](https://clash-bots.fandom.com/wiki/Clash_Bots) is a highly acclaimed Chinese TV series aired in 2018 that attracted over one billion views worldwide, featuring international heavyweight robots (110 kg) competing in a variety of challenges, drawing from a unique format that mixed battles, rumbles, and demolition tasks.
- I Led a highly skilled team of four, applying agile project management techniques to streamline the robot's design, construction, and testing stages, ensuring the project was delivered within a tight eight-month timeline.
- I designed impact-resistance mechanism, implemented RF control systems, executed welding and wiring, and assembled electro-mechanical components such as motors, contactors, and torque limiters to enhance combat performance.
- Tools utilized: Creo.
- Affiliated skills: Welding, Electronice, Mechanism Design, Project Management.

<p align="center">
  <img src="/assets/gif/clashbots_optimized.gif" alt="Clash Bots demo" width="600" /> 
</p>
<p align="center" style="font-size: 10px;">
  <em>Clash Bots demo</em>
</p>


<!-- ### R&D Engineer at Dynacolor
- materials under maintainance -->




<!--  -->
## üí° Why Me?

What sets me apart is not just my technical expertise but also my passion for learning and innovation. My experiences at NIH, LCSR, alongside numerous projects, have honed my quick learning abilities and fostered a strong capacity for collaboration. These experiences have equipped me with a problem-solving mindset and the ability to work effectively under pressure.

## üîç Looking Ahead

I am keen on contributing to impactful projects, especially in areas like advanced robotics, automation technologies, and computer vision. I'm ready to leverage my skills to make a significant contribution.

For collaborations or opportunities, feel free to reach out via email at chuan120@jhu.edu or my [LinkedIn](https://www.linkedin.com/in/chingyangh/). Let's explore how we can drive innovation forward together.

## üìä My Github stats

![](http://github-profile-summary-cards.vercel.app/api/cards/profile-details?username=AustinHuang823&theme=city_lights)

![](http://github-profile-summary-cards.vercel.app/api/cards/repos-per-language?username=AustinHuang823&theme=city_lights)
&nbsp;&nbsp;&nbsp;
![](http://github-profile-summary-cards.vercel.app/api/cards/stats?username=AustinHuang823&theme=city_lights)
<!-- {Templates} -->

<!-- Collapsible Sections -->
<!-- <details>
  <summary><b>Projects</b></summary>
  <p>Description of projects here...</p>
</details> -->

<!-- Adding Visuals and GIFs -->
<!-- ![Project Demo](url_to_gif) -->



<!--
**AustinHuang823/AustinHuang823** is a ‚ú® _special_ ‚ú® repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- üî≠ I‚Äôm currently working on ...
- üå± I‚Äôm currently learning ...
- üëØ I‚Äôm looking to collaborate on ...
- ü§î I‚Äôm looking for help with ...
- üí¨ Ask me about ...
- üì´ How to reach me: ...
- üòÑ Pronouns: ...
- ‚ö° Fun fact: ...
-->
